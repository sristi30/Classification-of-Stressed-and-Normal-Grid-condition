{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \"HW_TESLA.xlt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      STATIC  ADELANTO  MARKETPL  MCCULLGH   RINALDI    TOLUCA  VICTORVL  \\\n",
      "0          0  -5.94141  -1.00504  -1.00504 -10.37202 -11.67639  -6.28877   \n",
      "1          0  -5.98607  -1.01218  -1.01218 -10.43763 -11.74226  -6.33349   \n",
      "2          0  -6.03088  -1.01937  -1.01937 -10.50348 -11.80837  -6.37838   \n",
      "3          0  -6.07584  -1.02659  -1.02659 -10.56956 -11.87472  -6.42342   \n",
      "4          0  -6.12096  -1.03385  -1.03385 -10.63587 -11.94132  -6.46862   \n",
      "5          0  -6.16623  -1.04116  -1.04116 -10.70239 -12.00812  -6.51398   \n",
      "6          0  -6.21166  -1.04850  -1.04850 -10.76914 -12.07517  -6.55949   \n",
      "7          0  -6.25725  -1.05588  -1.05588 -10.83612 -12.14246  -6.60516   \n",
      "8          0  -6.30299  -1.06330  -1.06330 -10.90334 -12.20999  -6.65100   \n",
      "9          0  -6.34885  -1.07077  -1.07077 -10.97065 -12.27762  -6.69694   \n",
      "10         0  -6.39490  -1.07826  -1.07826 -11.03832 -12.34563  -6.74308   \n",
      "11         0  -6.44108  -1.08579  -1.08579 -11.10618 -12.41383  -6.78936   \n",
      "12         0  -6.48743  -1.09335  -1.09335 -11.17429 -12.48229  -6.83581   \n",
      "13         0  -6.53395  -1.10096  -1.10096 -11.24265 -12.55103  -6.88243   \n",
      "14         0  -6.58061  -1.10860  -1.10860 -11.31123 -12.61998  -6.92920   \n",
      "15         0  -6.62745  -1.11627  -1.11627 -11.38005 -12.68919  -6.97614   \n",
      "16         0  -6.67447  -1.12399  -1.12399 -11.44915 -12.75868  -7.02326   \n",
      "17         0  -6.72165  -1.13176  -1.13176 -11.51849 -12.82844  -7.07056   \n",
      "18         0  -6.76903  -1.13958  -1.13958 -11.58812 -12.89848  -7.11805   \n",
      "19         0  -6.81621  -1.14740  -1.14740 -11.65720 -12.96792  -7.16533   \n",
      "20         0  -6.86391  -1.15529  -1.15529 -11.72730 -13.03847  -7.21315   \n",
      "21         0  -6.91180  -1.16323  -1.16323 -11.79768 -13.10929  -7.26116   \n",
      "22         0  -6.96057  -1.17118  -1.17118 -11.86980 -13.18202  -7.31011   \n",
      "23         0  -7.00875  -1.17922  -1.17922 -11.94052 -13.25318  -7.35841   \n",
      "24         0  -7.05711  -1.18729  -1.18729 -12.01151 -13.32462  -7.40689   \n",
      "25         0  -7.10565  -1.19542  -1.19542 -12.08273 -13.39631  -7.45556   \n",
      "26         0  -7.15436  -1.20359  -1.20359 -12.15420 -13.46824  -7.50439   \n",
      "27         0  -7.20319  -1.21180  -1.21180 -12.22578 -13.54023  -7.55334   \n",
      "28         0  -7.25228  -1.22006  -1.22006 -12.29781 -13.61275  -7.60257   \n",
      "29         0  -7.30158  -1.22837  -1.22837 -12.37014 -13.68558  -7.65200   \n",
      "...      ...       ...       ...       ...       ...       ...       ...   \n",
      "1606       0 -10.04445  -4.80244  -4.80244 -14.97856 -16.38641 -10.36699   \n",
      "1607       0  -9.48184  -4.02405  -4.02405 -14.47568 -15.87417  -9.80887   \n",
      "1608       0  -8.91540  -3.23557  -3.23557 -13.97241 -15.36194  -9.24715   \n",
      "1609       0  -8.34305  -2.43578  -2.43578 -13.46496 -14.84550  -8.67964   \n",
      "1610       0  -7.76208  -1.62153  -1.62153 -12.95116 -14.32288  -8.10368   \n",
      "1611       0  -6.57294   0.05605   0.05605 -11.90533 -13.26000  -6.92520   \n",
      "1612       0  -5.96004   0.92541   0.92541 -11.36891 -12.71532  -6.31797   \n",
      "1613       0  -5.33390   1.81795   1.81795 -10.82324 -12.16165  -5.69779   \n",
      "1614       0 -10.17281  -4.87178  -4.87178 -15.13889 -16.54272 -10.49598   \n",
      "1615       0  -9.61115  -4.09329  -4.09329 -14.63762 -16.03217  -9.93884   \n",
      "1616       0  -9.04502  -3.30450  -3.30450 -14.13468 -15.52017  -9.37743   \n",
      "1617       0  -8.47343  -2.50445  -2.50445 -13.62846 -15.00506  -8.81071   \n",
      "1618       0  -7.89307  -1.68988  -1.68988 -13.11558 -14.48334  -8.23538   \n",
      "1619       0  -6.70505  -0.01129  -0.01129 -12.07180 -13.42260  -7.05808   \n",
      "1620       0  -6.09275   0.85865   0.85865 -11.53639 -12.87896  -6.45148   \n",
      "1621       0  -5.46737   1.75209   1.75209 -10.99221 -12.32683  -5.83211   \n",
      "1622       0 -10.30228  -4.94156  -4.94156 -15.30101 -16.70090 -10.62610   \n",
      "1623       0  -9.74174  -4.16289  -4.16289 -14.80163 -16.19229 -10.07013   \n",
      "1624       0  -9.17537  -3.37370  -3.37370 -14.29805 -15.67960  -9.50847   \n",
      "1625       0  -8.60443  -2.57342  -2.57342 -13.79275 -15.16538  -8.94242   \n",
      "1626       0  -8.02488  -1.75856  -1.75856 -13.28119 -14.64505  -8.36793   \n",
      "1627       0  -6.83770  -0.07885  -0.07885 -12.23897 -13.58590  -7.19151   \n",
      "1628       0  -6.22593   0.79173   0.79173 -11.70455 -13.04329  -6.58547   \n",
      "1629       0  -5.60179   1.68560   1.68560 -11.16236 -12.49322  -5.96739   \n",
      "1630       0 -10.43301  -5.01174  -5.01174 -15.46511 -16.86119 -10.75753   \n",
      "1631       0  -9.87218  -4.23270  -4.23270 -14.96497 -16.35169 -10.20125   \n",
      "1632       0  -8.15712  -1.82753  -1.82753 -13.44717 -14.80708  -8.50089   \n",
      "1633       0  -6.97114  -0.14668  -0.14668 -12.40724 -13.75034  -7.32574   \n",
      "1634       0  -6.36008   0.72444   0.72444 -11.87406 -13.20900  -6.72045   \n",
      "1635       0  -5.73691   1.61875   1.61875 -11.33325 -12.66026  -6.10335   \n",
      "\n",
      "      RINALDI2   ADELSVC  MKTPSVC   ...      Ir3442   Ii3442   Ir3458  \\\n",
      "0    -10.16440  -5.94141 -1.00504   ...    -2.08603  0.54514  6.00502   \n",
      "1    -10.22944  -5.98607 -1.01218   ...    -2.08770  0.55421  6.01975   \n",
      "2    -10.29470  -6.03088 -1.01937   ...    -2.08938  0.56335  6.03453   \n",
      "3    -10.36020  -6.07584 -1.02659   ...    -2.09109  0.57256  6.04935   \n",
      "4    -10.42592  -6.12096 -1.03385   ...    -2.09281  0.58185  6.06419   \n",
      "5    -10.49185  -6.16623 -1.04116   ...    -2.09454  0.59117  6.07907   \n",
      "6    -10.55801  -6.21166 -1.04850   ...    -2.09628  0.60058  6.09399   \n",
      "7    -10.62439  -6.25725 -1.05588   ...    -2.09804  0.61002  6.10896   \n",
      "8    -10.69102  -6.30299 -1.06330   ...    -2.09982  0.61956  6.12396   \n",
      "9    -10.75774  -6.34885 -1.07077   ...    -2.10164  0.62880  6.13887   \n",
      "10   -10.82481  -6.39490 -1.07826   ...    -2.10345  0.63845  6.15396   \n",
      "11   -10.89206  -6.44108 -1.08579   ...    -2.10527  0.64819  6.16908   \n",
      "12   -10.95957  -6.48743 -1.09335   ...    -2.10711  0.65800  6.18424   \n",
      "13   -11.02733  -6.53395 -1.10096   ...    -2.10897  0.66789  6.19946   \n",
      "14   -11.09529  -6.58061 -1.10860   ...    -2.11082  0.67799  6.21470   \n",
      "15   -11.16351  -6.62745 -1.11627   ...    -2.11267  0.68821  6.22998   \n",
      "16   -11.23199  -6.67447 -1.12399   ...    -2.11455  0.69850  6.24531   \n",
      "17   -11.30072  -6.72165 -1.13176   ...    -2.11644  0.70891  6.26068   \n",
      "18   -11.36972  -6.76903 -1.13958   ...    -2.11836  0.71941  6.27611   \n",
      "19   -11.43820  -6.81621 -1.14740   ...    -2.12039  0.72845  6.29099   \n",
      "20   -11.50768  -6.86391 -1.15529   ...    -2.12233  0.73924  6.30649   \n",
      "21   -11.57742  -6.91180 -1.16323   ...    -2.12427  0.75012  6.32203   \n",
      "22   -11.64889  -6.96057 -1.17118   ...    -2.12611  0.76470  6.33837   \n",
      "23   -11.71898  -7.00875 -1.17922   ...    -2.12812  0.77527  6.35380   \n",
      "24   -11.78933  -7.05711 -1.18729   ...    -2.13014  0.78586  6.36927   \n",
      "25   -11.85992  -7.10565 -1.19542   ...    -2.13221  0.79628  6.38473   \n",
      "26   -11.93076  -7.15436 -1.20359   ...    -2.13428  0.80691  6.40021   \n",
      "27   -12.00170  -7.20319 -1.21180   ...    -2.13630  0.81769  6.41564   \n",
      "28   -12.07309  -7.25228 -1.22006   ...    -2.13838  0.82859  6.43122   \n",
      "29   -12.14478  -7.30158 -1.22837   ...    -2.14049  0.83955  6.44684   \n",
      "...        ...       ...      ...   ...         ...      ...      ...   \n",
      "1606 -14.76346 -10.04445 -4.80244   ...    -3.86143  1.04360  6.60036   \n",
      "1607 -14.25792  -9.48184 -4.02405   ...    -3.48458  0.99978  6.57283   \n",
      "1608 -13.75185  -8.91540 -3.23557   ...    -3.10429  0.96480  6.54642   \n",
      "1609 -13.24152  -8.34305 -2.43578   ...    -2.72050  0.92787  6.51874   \n",
      "1610 -12.72475  -7.76208 -1.62153   ...    -2.33235  0.89908  6.49067   \n",
      "1611 -11.67263  -6.57294  0.05605   ...    -1.54206  0.85273  6.43327   \n",
      "1612 -11.13286  -5.96004  0.92541   ...    -1.13692  0.84209  6.40349   \n",
      "1613 -10.58368  -5.33390  1.81795   ...    -0.72465  0.83715  6.37299   \n",
      "1614 -14.92278 -10.17281 -4.87178   ...    -3.88845  1.06608  6.63356   \n",
      "1615 -14.41883  -9.61115 -4.09329   ...    -3.51162  1.02326  6.60686   \n",
      "1616 -13.91308  -9.04502 -3.30450   ...    -3.13143  0.98734  6.58040   \n",
      "1617 -13.40397  -8.47343 -2.50445   ...    -2.74771  0.95068  6.55327   \n",
      "1618 -12.88811  -7.89307 -1.68988   ...    -2.35958  0.92175  6.52552   \n",
      "1619 -11.83801  -6.70505 -0.01129   ...    -1.56922  0.87562  6.46896   \n",
      "1620 -11.29923  -6.09275  0.85865   ...    -1.16390  0.86567  6.43954   \n",
      "1621 -10.75152  -5.46737  1.75209   ...    -0.75147  0.86047  6.40960   \n",
      "1622 -15.08386 -10.30228 -4.94156   ...    -3.91539  1.09053  6.66745   \n",
      "1623 -14.58177  -9.74174 -4.16289   ...    -3.53854  1.04995  6.64144   \n",
      "1624 -14.07540  -9.17537 -3.37370   ...    -3.15868  1.01038  6.61460   \n",
      "1625 -13.56721  -8.60443 -2.57342   ...    -2.77498  0.97354  6.58776   \n",
      "1626 -13.05266  -8.02488 -1.75856   ...    -2.38693  0.94495  6.56060   \n",
      "1627 -12.00407  -6.83770 -0.07885   ...    -1.59629  0.89957  6.50466   \n",
      "1628 -11.46628  -6.22593  0.79173   ...    -1.19088  0.88941  6.47565   \n",
      "1629 -10.92053  -5.60179  1.68560   ...    -0.77853  0.88439  6.44632   \n",
      "1630 -15.24691 -10.43301 -5.01174   ...    -3.94232  1.11772  6.70176   \n",
      "1631 -14.74407  -9.87218 -4.23270   ...    -3.56580  1.07332  6.67529   \n",
      "1632 -13.21756  -8.15712 -1.82753   ...    -2.41448  0.96714  6.59533   \n",
      "1633 -12.17124  -6.97114 -0.14668   ...    -1.62342  0.92392  6.54051   \n",
      "1634 -11.63466  -6.36008  0.72444   ...    -1.21799  0.91382  6.51192   \n",
      "1635 -11.09028  -5.73691  1.61875   ...    -0.80568  0.90834  6.48300   \n",
      "\n",
      "       Ii3458   Ir3497   Ii3497   Ir3710   Ii3710   Ir3850   Ii3850  \n",
      "0    -0.66981  4.29558  0.04612  4.58774 -0.85948  6.45435  0.03891  \n",
      "1    -0.67443  4.29190  0.03598  4.60209 -0.86684  6.48647  0.03493  \n",
      "2    -0.67907  4.28821  0.02578  4.61644 -0.87425  6.51864  0.03091  \n",
      "3    -0.68372  4.28450  0.01553  4.63081 -0.88171  6.55087  0.02687  \n",
      "4    -0.68847  4.28079  0.00523  4.64519 -0.88921  6.58315  0.02279  \n",
      "5    -0.69328  4.27706 -0.00515  4.65958 -0.89673  6.61549  0.01870  \n",
      "6    -0.69807  4.27332 -0.01560  4.67397 -0.90430  6.64788  0.01458  \n",
      "7    -0.70291  4.26956 -0.02613  4.68838 -0.91189  6.68032  0.01043  \n",
      "8    -0.70783  4.26580 -0.03669  4.70280 -0.91952  6.71282  0.00625  \n",
      "9    -0.71289  4.26193 -0.04741  4.71724 -0.92698  6.74535  0.00228  \n",
      "10   -0.71780  4.25817 -0.05789  4.73162 -0.93490  6.77798 -0.00185  \n",
      "11   -0.72269  4.25445 -0.06824  4.74594 -0.94301  6.81067 -0.00590  \n",
      "12   -0.72762  4.25071 -0.07865  4.76027 -0.95119  6.84341 -0.00998  \n",
      "13   -0.73258  4.24696 -0.08911  4.77461 -0.95938  6.87622 -0.01411  \n",
      "14   -0.73763  4.24320 -0.09965  4.78896 -0.96762  6.90908 -0.01823  \n",
      "15   -0.74269  4.23942 -0.11027  4.80331 -0.97590  6.94200 -0.02240  \n",
      "16   -0.74779  4.23563 -0.12094  4.81768 -0.98424  6.97499 -0.02660  \n",
      "17   -0.75297  4.23184 -0.13167  4.83206 -0.99260  7.00802 -0.03083  \n",
      "18   -0.75816  4.22802 -0.14249  4.84644 -1.00103  7.04113 -0.03510  \n",
      "19   -0.76387  4.22411 -0.15234  4.86046 -1.00984  7.07429 -0.03777  \n",
      "20   -0.76918  4.22027 -0.16329  4.87486 -1.01835  7.10751 -0.04208  \n",
      "21   -0.77449  4.21641 -0.17433  4.88927 -1.02688  7.14079 -0.04643  \n",
      "22   -0.77813  4.21284 -0.18474  4.90374 -1.03691  7.17451 -0.05182  \n",
      "23   -0.78386  4.20884 -0.19602  4.91818 -1.04524  7.20789 -0.05591  \n",
      "24   -0.78957  4.20485 -0.20719  4.93258 -1.05381  7.24135 -0.05995  \n",
      "25   -0.79541  4.20082 -0.21839  4.94698 -1.06241  7.27489 -0.06389  \n",
      "26   -0.80129  4.19677 -0.22967  4.96139 -1.07102  7.30848 -0.06785  \n",
      "27   -0.80739  4.19267 -0.24111  4.97580 -1.07953  7.34209 -0.07173  \n",
      "28   -0.81340  4.18859 -0.25253  4.99022 -1.08824  7.37582 -0.07574  \n",
      "29   -0.81944  4.18448 -0.26406  5.00465 -1.09702  7.40962 -0.07980  \n",
      "...       ...      ...      ...      ...      ...      ...      ...  \n",
      "1606 -1.20336  4.63059 -0.44642  4.39652 -1.26732  6.55954 -0.46688  \n",
      "1607 -1.11933  4.52184 -0.40317  4.53121 -1.23295  6.75374 -0.38139  \n",
      "1608 -1.03173  4.41196 -0.36292  4.66792 -1.19717  6.95058 -0.29217  \n",
      "1609 -0.94412  4.30004 -0.32555  4.80653 -1.15773  7.15005 -0.19483  \n",
      "1610 -0.85490  4.18663 -0.29112  4.94698 -1.11485  7.35184 -0.09008  \n",
      "1611 -0.66850  3.95470 -0.22827  5.23428 -1.02172  7.76438  0.14130  \n",
      "1612 -0.57035  3.83598 -0.19915  5.38164 -0.97151  7.97493  0.26534  \n",
      "1613 -0.46834  3.71505 -0.17183  5.53204 -0.91872  8.18936  0.39673  \n",
      "1614 -1.22523  4.63251 -0.47244  4.41895 -1.29203  6.61986 -0.48998  \n",
      "1615 -1.14071  4.52391 -0.43056  4.55440 -1.25707  6.81461 -0.40521  \n",
      "1616 -1.05332  4.41412 -0.39029  4.69137 -1.22100  7.01209 -0.31443  \n",
      "1617 -0.96534  4.30246 -0.35312  4.83036 -1.18163  7.21231 -0.21653  \n",
      "1618 -0.87590  4.18918 -0.31910  4.97123 -1.13843  7.41481 -0.11083  \n",
      "1619 -0.68833  3.95790 -0.25549  5.25916 -1.04634  7.82857  0.12003  \n",
      "1620 -0.58986  3.83940 -0.22648  5.40693 -0.99614  8.03986  0.24455  \n",
      "1621 -0.48722  3.71864 -0.19920  5.55789 -0.94365  8.25535  0.37633  \n",
      "1622 -1.24699  4.63437 -0.49980  4.44169 -1.31671  6.68019 -0.51506  \n",
      "1623 -1.16112  4.52613 -0.45732  4.57741 -1.28278  6.87591 -0.42971  \n",
      "1624 -1.07508  4.41624 -0.41787  4.71476 -1.24530  7.07377 -0.33719  \n",
      "1625 -0.98685  4.30470 -0.38110  4.85417 -1.20559  7.27468 -0.23837  \n",
      "1626 -0.89708  4.19173 -0.34729  4.99544 -1.16251  7.47796 -0.13215  \n",
      "1627 -0.70859  3.96100 -0.28309  5.28396 -1.07107  7.89283  0.09853  \n",
      "1628 -0.60969  3.84274 -0.25391  5.43211 -1.02119  8.10482  0.22311  \n",
      "1629 -0.50649  3.72222 -0.22693  5.58362 -0.96888  8.32139  0.35553  \n",
      "1630 -1.26793  4.63625 -0.52673  4.46431 -1.34269  6.74092 -0.54067  \n",
      "1631 -1.18342  4.52792 -0.48494  4.60036 -1.30740  6.93701 -0.45349  \n",
      "1632 -0.91883  4.19416 -0.37483  5.01926 -1.18722  7.54130 -0.15254  \n",
      "1633 -0.72913  3.96399 -0.31099  5.30873 -1.09614  7.95728  0.07662  \n",
      "1634 -0.62965  3.84602 -0.28159  5.45726 -1.04666  8.17001  0.20119  \n",
      "1635 -0.52638  3.72564 -0.25509  5.60929 -0.99410  8.38750  0.33457  \n",
      "\n",
      "[1636 rows x 133 columns]\n",
      "(2514, 133)\n",
      "(4150, 133)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel (r'HW_TESLA.xlt') \n",
    "print(df.iloc[0:1636].shape) #label 0 data\n",
    "print(df.iloc[1636:].shape) #label 1 data\n",
    "print (df.shape)\n",
    "#train=df.iloc[1636:].sample(frac=0.75,random_state=200)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3112, 133)\n",
      "(1038, 133)\n"
     ]
    }
   ],
   "source": [
    "#splitting into train and test  and val\n",
    "train=df.sample(frac=0.75,random_state=200) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "# test = test_.sample(frac=0.5,random_state=200) #random state is a seed value\n",
    "# val = test_.drop(test.index)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train.columns[1:])\n",
    "x_train = train[features]\n",
    "y_train = train['STATIC']\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(x_train)\n",
    "\n",
    "# pca.components_\n",
    "\n",
    "#transform the train data inro principal components\n",
    "train_x = pca.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_val = val[features]\n",
    "# y_val = val['STATIC']\n",
    "# #convert val into principal components\n",
    "# val_x = pca.transform(x_val)\n",
    "x_test = test[features]\n",
    "y_test = test['STATIC']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training classifier for transformed training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "0.9832904884318766\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "0.9858611825192802\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "0.9652956298200515\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
      "0.9755784061696658\n",
      "Best Validation Accuracy :  0.9858611825192802\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle = True, random_state=200)\n",
    "mean_accuracy = 0\n",
    "# train_x = train_x.values # to convert df to numpy arrays\n",
    "train_y = y_train.values\n",
    "best_accuracy = 0\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    kx_train= train_x[train_index]\n",
    "    kx_test = train_x[test_index]\n",
    "    ky_train, ky_test = train_y[train_index], train_y[test_index]\n",
    "    #-------------------------------------------para search by grid search\n",
    "    param_grid = {'max_depth': np.arange(3, 6),'min_samples_split':np.arange(2,4),'min_samples_leaf':np.arange(1,4),\n",
    "              'criterion':['gini','entropy']}\n",
    "    tree = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
    "    tree.fit(kx_train, ky_train)\n",
    "    tree_preds = tree.predict_proba(kx_test)[:, 1]\n",
    "    tree_performance = roc_auc_score(ky_test, tree_preds)\n",
    "    print(tree.best_params_)\n",
    "    #------------------------------------------------------\n",
    "    # Decision tree with best parameters\n",
    "    best_dp = tree.best_params_['max_depth']\n",
    "    min_smple_split = tree.best_params_['min_samples_split']\n",
    "    min_smple_lf = tree.best_params_['min_samples_leaf']\n",
    "    best_crit = tree.best_params_['criterion']\n",
    "    dt = DecisionTreeClassifier(min_samples_split = min_smple_split,min_samples_leaf=min_smple_split\n",
    "                                ,max_depth = best_dp, criterion = best_crit)\n",
    "    dt.fit(kx_train, ky_train)\n",
    "    y_pred = dt.predict(kx_test)\n",
    "    acc = metrics.accuracy_score(ky_test, y_pred)\n",
    "    print(acc)\n",
    "    if(acc > best_accuracy):\n",
    "        best_accuracy = acc\n",
    "        with open('best_pca_dt.pkl', 'wb') as f:\n",
    "            pickle.dump(dt, f)            \n",
    "    mean_accuracy += acc\n",
    "mean_accuracy /= 4\n",
    "print(\"Best Validation Accuracy : \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9701348747591522\n",
      "398 9 22 609\n"
     ]
    }
   ],
   "source": [
    "#convert val into principal components\n",
    "test_x = pca.transform(x_test)\n",
    "# Load the pickled model \n",
    "with open('best_pca_dt.pkl', 'rb') as f:\n",
    "    model_from_pickle = pickle.load(f)\n",
    "# Use the loaded pickled model to make predictions \n",
    "y_pred = model_from_pickle.predict(test_x)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903743315508022\n",
      "0.9947312961011592\n",
      "0.9968387776606955\n",
      "0.9935205183585313\n",
      "Best Validation Accuracy :  0.9961439588688946\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle = True, random_state=200)\n",
    "mean_accuracy = 0\n",
    "# train_x = train_x.values # to convert df to numpy arrays\n",
    "train_y = y_train.values\n",
    "best_accuracy = 0\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    kx_train= train_x[train_index]\n",
    "    kx_test = train_x[test_index]\n",
    "    ky_train, ky_test = train_y[train_index], train_y[test_index]\n",
    "#     #-------------------------------------------para search by grid search\n",
    "#     param_grid = {'decision_function_shape': ['ovo', 'ovr'],'max_iter':['-1'],\n",
    "#               'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'probability' : ['True']}\n",
    "#     model = GridSearchCV(svm.SVC(), param_grid)\n",
    "#     model.fit(kx_train, ky_train)\n",
    "#     tree_preds = model.predict_proba(kx_test)[:, 1]\n",
    "#     tree_performance = roc_auc_score(ky_test, tree_preds)\n",
    "# #     print('DecisionTree: Area under the ROC curve = {}'.format(tree_performance))\n",
    "#     print(tree.best_params_)\n",
    "#     #------------------------------------------------------\n",
    "    \n",
    "    # SVM\n",
    "    wght={0:1.5,1:1}\n",
    "    SVM = svm.SVC(kernel='linear',C=12,class_weight=wght)\n",
    "    SVM.fit(kx_train, ky_train)\n",
    "    y_pred = SVM.predict(kx_test)\n",
    "    acc = metrics.accuracy_score(ky_test, y_pred)\n",
    "    f1 = f1_score(ky_test, y_pred)\n",
    "    #print(acc)\n",
    "    print(f1)\n",
    "    if(acc > best_accuracy):\n",
    "        best_accuracy = acc\n",
    "        with open('best_pca_svm.pkl', 'wb') as f:\n",
    "            pickle.dump(SVM, f)            \n",
    "    mean_accuracy += acc\n",
    "mean_accuracy /= 4\n",
    "print(\"Best Validation Accuracy : \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9942196531791907\n",
      "0.9952229299363058\n",
      "407 0 6 625\n"
     ]
    }
   ],
   "source": [
    "# print(train_x.shape)\n",
    "# print(y_train.shape)\n",
    "SVM = svm.SVC(kernel='linear',C=12,class_weight=wght)\n",
    "SVM.fit(train_x, y_train)\n",
    "#test\n",
    "y_pred = SVM.predict(test_x)\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9942196531791907\n",
      "0.9952229299363058\n",
      "407 0 6 625\n"
     ]
    }
   ],
   "source": [
    "# SVM = svm.LinearSVC()\n",
    "# SVM.fit(train_x, y_train)\n",
    "# Load the pickled model \n",
    "with open('best_pca_svm.pkl', 'rb') as f:\n",
    "    model_from_pickle = pickle.load(f)\n",
    "# Use the loaded pickled model to make predictions \n",
    "y_pred = model_from_pickle.predict(test_x)\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9858611825192802\n",
      "0.9768637532133676\n",
      "0.9768637532133676\n",
      "0.980719794344473\n",
      "Best Validation Accuracy :  0.9858611825192802\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle = True, random_state=200)\n",
    "mean_accuracy = 0\n",
    "# train_x = train_x.values # to convert df to numpy arrays\n",
    "train_y = y_train.values\n",
    "best_accuracy = 0\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    kx_train= train_x[train_index]\n",
    "    kx_test = train_x[test_index]\n",
    "    ky_train, ky_test = train_y[train_index], train_y[test_index]\n",
    "    # Decision tree\n",
    "    RF = RandomForestClassifier(n_estimators=350, max_depth=5, random_state=99)\n",
    "    RF.fit(kx_train, ky_train)\n",
    "    y_pred = RF.predict(kx_test)\n",
    "    acc = metrics.accuracy_score(ky_test, y_pred)\n",
    "    print(acc)\n",
    "    if(acc > best_accuracy):\n",
    "        best_accuracy = acc\n",
    "        with open('best_pca_rf.pkl', 'wb') as f:\n",
    "            pickle.dump(RF, f)            \n",
    "    mean_accuracy += acc\n",
    "mean_accuracy /= 4\n",
    "print(\"Best Validation Accuracy : \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9855491329479769\n",
      "404 3 12 619\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RF = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "# RF.fit(train_x, y_train)\n",
    "with open('best_pca_rf.pkl', 'rb') as f:\n",
    "    model_from_pickle = pickle.load(f)\n",
    "\n",
    "y_pred = model_from_pickle.predict(test_x)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9922879177377892\n",
      "1.0\n",
      "0.9974293059125964\n",
      "0.9922879177377892\n",
      "Best Validation Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle = True, random_state=200)\n",
    "mean_accuracy = 0\n",
    "# train_x = train_x.values # to convert df to numpy arrays\n",
    "train_y = y_train.values\n",
    "best_accuracy = 0\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    kx_train= train_x[train_index]\n",
    "    kx_test = train_x[test_index]\n",
    "    ky_train, ky_test = train_y[train_index], train_y[test_index]\n",
    "    # multi layer perceptron\n",
    "    NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10,1), random_state=1)\n",
    "    NN.fit(kx_train, ky_train)\n",
    "    y_pred = NN.predict(kx_test)\n",
    "    acc = metrics.accuracy_score(ky_test, y_pred)\n",
    "    print(acc)\n",
    "    if(acc > best_accuracy):\n",
    "        best_accuracy = acc\n",
    "        with open('best_pca_nn.pkl', 'wb') as f:\n",
    "            pickle.dump(NN, f)            \n",
    "    mean_accuracy += acc\n",
    "mean_accuracy /= 4\n",
    "print(\"Best Validation Accuracy : \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9951830443159922\n",
      "405 2 3 628\n"
     ]
    }
   ],
   "source": [
    "with open('best_pca_nn.pkl', 'rb') as f:\n",
    "    NN = pickle.load(f)\n",
    "y_pred = NN.predict(test_x)\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897172236503856\n",
      "0.9987146529562982\n",
      "0.9974293059125964\n",
      "0.9974293059125964\n",
      "Best Validation Accuracy :  0.9987146529562982\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle = True, random_state=200)\n",
    "mean_accuracy = 0\n",
    "# x_train = x_train.values # to convert df to numpy arrays\n",
    "train_y = y_train.values\n",
    "best_accuracy = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    kx_train= x_train[train_index]\n",
    "    kx_test = x_train[test_index]\n",
    "    ky_train, ky_test = train_y[train_index], train_y[test_index]\n",
    "    # multi layer perceptron\n",
    "    NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8, 2), random_state=1)\n",
    "    NN.fit(kx_train, ky_train)\n",
    "    y_pred = NN.predict(kx_test)\n",
    "    acc = metrics.accuracy_score(ky_test, y_pred)\n",
    "    print(acc)\n",
    "    if(acc > best_accuracy):\n",
    "        best_accuracy = acc\n",
    "        with open('best_nn.pkl', 'wb') as f:\n",
    "            pickle.dump(NN, f)            \n",
    "    mean_accuracy += acc\n",
    "mean_accuracy /= 4\n",
    "print(\"Best Validation Accuracy : \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9971098265895953\n",
      "407 0 3 628\n"
     ]
    }
   ],
   "source": [
    "#without pca on data mlp\n",
    "with open('best_nn.pkl', 'rb') as f:\n",
    "    NN = pickle.load(f)\n",
    "# NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 2), random_state=1)\n",
    "# NN.fit(x_train, y_train)\n",
    "y_pred = NN.predict(x_test)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test using random 60 data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 133)\n"
     ]
    }
   ],
   "source": [
    "final_test = df.sample(60)\n",
    "print(final_test.shape)\n",
    "x_final_test = final_test[features]\n",
    "y_final_test = final_test['STATIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n",
      "21 0 0 39\n"
     ]
    }
   ],
   "source": [
    "#transform x_final_test to pca coeff\n",
    "final_test_x = pca.transform(x_final_test)\n",
    "#load best model\n",
    "with open('best_pca_nn.pkl', 'rb') as f:\n",
    "    NN = pickle.load(f)\n",
    "#predict using loaded model\n",
    "y_pred = NN.predict(final_test_x)\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_final_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_final_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
